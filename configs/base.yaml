algo: ppo
total_timesteps: 8
n_envs: 8
frame_stack: 4
seed: 0
learning_rate: 2.5e-4
n_steps: 128
batch_size: 256
n_epochs: 4
gamma: 0.99
ent_coef: 0.01
clip_range: 0.1
device: cuda
checkpoint_freq: 100000
eval_freq: 200000
n_eval_episodes: 10
early_stop:
enabled: true
patience: 5 # number of consecutive evals with no improvement
min_delta: 1.0 # minimum improvement in eval reward to count